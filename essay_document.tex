\documentclass[a4paper, 12pt, titlepage]{scrartcl} 
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage[onehalfspacing]{setspace} %sollte 1,5 Zeilenabstand erzeugen
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2.5cm,includeheadfoot]{geometry}

\usepackage{acronym}
\usepackage[babel,german=guillemets]{csquotes}
\usepackage[style=ieee]{biblatex} %[style=alphabetic oder numeric etc.,backend=biber]
\bibliography{essay_document_biblio}

\begin{document}
\author{Anne Borchard}
\title{Ethische Anforderungen an autonom fahrende Personenkraftwagen im Stra\ss enverkehr}
\publishers{Humboldt-Universit\"at zu Berlin}
\maketitle
\tableofcontents
\newpage

\section*{Abk\"urzungsverzeichnis}
\begin{acronym}
	\acro{AA}{Autonomer Agent}
	\acro{IRA}{Intelligent Road Agent}
	\acro{StVO}{Stra\ss enverkehrs-Ordnung}
\end{acronym}
\newpage

\section{Einleitung}
	IRA (Intelligent Road Agent)\footnote{Fiktives, voll-autonomes Assistenzsystem} fährt in einer regnerischen Nach durch die Stadt. Die Straßen sind leer und sie kann die Ampelschaltung optimal nutzen. Direkt nach einer Kurve sieht IRA auf der Straße zwei Frauen und bremst. Nasses Laub verl\"angert den Bremsweg drastisch, IRA hat nur folgende Optionen: bei Beibehaltung des Kurses beide Frauen treffen oder sich f\"ur eine Frau als Ziel entscheiden. Die Entscheidung fällt auf die \"Ubergewichtige (Bezeichnung: A), da sie voraussichtlich eine geringere Lebenserwartung hat als die andere Frau. A stirbt an Ort und Stelle. IRA hat ihre Insassen geschützt und ihren Algorithmen entsprechend gehandelt. Leider war A nicht übergewichtig, sondern hochschwanger. Die Angehörigen von A werden versuchen, den Automobilhersteller für ihren Verlust haftbar zu machen.
	
	Dieses Dilemma kann sich, wenn auch mit geringer Wahrscheinlichkeit, in einer Zukunft mit autonom fahrenden Fahrzeugen zutragen. Es zeigt, dass eine Auseinandersetzung mit den moralischen Dimensionen des autonomen Fahrens n\"otig ist. Welche ethischen Richtlinien sollen solche Fahrzeuge befolgen? Wer entscheidet dar\"uber? Wie k\"onnen Dilemma dieser Art gel\"ost werden? Besteht \"uberhaupt Konsens \"uber die \glqq richtige\grqq{} Ethik?
\section{Begriffe und Annahmen}
	Im folgendem Essay werden die Begriffe AA (autonomer Agent) und autonom fahrendes Fahrzeug synonym verwendet. Da es in der Literatur verschiedenen Graden der Automatisierung gibt, wird implizit vom h\"ochsten Grad\footnote{Laut Bundesministerium für Verkehr und digitale Infrastruktur: Fahrerloses Fahren, Insassen sind reine Passagiere (vgl. \autocite{bmvi2015}, S. 6).} ausgegangen. Zudem wird angenommen, dass der AA fehlerfrei funktioniert\footnote{Implementierungsfehler, fehlerhafte Sensoren oder unbefugte Eingriffe von Au\ss en werden ausgeschlo\ss en, sodass der AA in einem idealen Umfeld agieren kann.}.
	
	Um in Deutschland ein Fahrzeug im \"offentlichen Stra\ss enverkehr bewegen zu d\"urfen, ist, sofern nicht anders vermerkt, eine Fahrerlaubnis n\"otig. Das Regelwerk hierzu bildet die FeV (Fahrerlaubnis-Verordnung). Ziel ist es, sowohl das Fahrzeug kontrollieren als auch im Rahmen der StVO (Stra\ss enverkehrs-Ordnung) am Stra\ss enverkehr teilnehmen zu k\"onnen.
	
	Da sich das Essay an Personen aus dem Bereich der Informatik richtet, werden im Folgenden zwei hierf\"ur relevante Formen der Ethik kurz dargestellt.Zun\"achst wird die \emph{Deontologische Ethik} erl\"autert, welche auch als \emph{Deontologie} bezeichnet wird. Dabei handelt es sich um eine moralische Handlungsanweisung, welche eine strikte Befolgung von Regeln oder auch Pflichten verlangt (vgl. \autocite{baase:fire}, S. 47). Die Konsequenzen einer Handlung, egal ob im Allgemeinen als w\"unschenswert angesehen oder nicht, werden nicht betrachtet. Des weiteren ist die \emph{Utilitaristischen Ethik} als Auspr\"agung der \emph{Konsequenzialistische Ethik} wichtiger Bestandteil folgender Kapitel. Hierbei werden moralische Entscheidungen ausschlie\ss lich anhand ihrer direkten und indirekten Folgen getroffen. Baase \autocite{baase:fire} formuliert wie folgt: \glqq we consider the impact on utility and judge the action by its net impact\grqq{} (\autocite{baase:fire}, S. 48).
\section{Grundlegende Problematik}
	Zu den angestrebten Zielen durch die Verwendung von AA geh\"oren die drastische Reduzierung von Verkehrstoten, die effizientere Nutzung der Infrastruktur und das Integrieren von Personenkreisen, welche zuvor nicht am Stra\ss enverkehr ungehindert teilnehmen konnten. Die Einf\"uhrung von AA ist unter Betrachtung dieser Aspekte f\"ur weite Teile der Bev\"olkerung w\"unschenswert. Im Gegensatz zu einem menschlichen Fahrer werden an einen AA offensichtlich Anforderungen gestellt, welche \"uber technische Aspekte hinaus gehen. N\"urnberger \autocite{nunu2016} formuliert diesen Aspekt treffend: \glqq Interessanter Weise haben wir an Algorithmen höhere ethische Ansprüche als an uns selbst\grqq{} (\cite{nunu2016}, S. 2).
	
	Den erhofften Vorz\"uge stehen jedoch einer neuen Problematik gegen\"uber. Ein AA kann in einer wie in der Einleitung geschilderten Situation \emph{Entscheidungen treffen}, w\"ahrend ein menschlicher Fahrer in Bruchteilen von Sekunden fast ausschlie\ss lich \emph{reagieren} kann. Der Programmierer\footnote{Aus Gr\"unden der Lesbarkeit wird in vielen F\"allen die maskuline Form eines Wortes gew\"ahlt, jedoch sind beide Geschlechter angesprochen.} des Entscheidungsalgorithmus h\"atte genug Zeit im Voraus, einen Ablaufplan f\"ur diverse Situationen vorzugeben. Es besteht Unklarheit dar\"uber, welche ethischen Richtlinien bei der Entscheidungsfindung zu beachten sind und ob diese auch gesellschaftliche akzeptiert werden. Im Folgenden werden verschiedene ethische Sichtweisen auf die geschilderte Problematik und teilweise auch L\"osungsvorschl\"age erl\"autert.   
\section{Deontologische Sichtweise}
	Eine deontologische Ethik scheint keine L\"osung f\"ur Dilemma-Situationen zu bieten. Regeln wie die StVO k\"onnen als Rahmen f\"ur \emph{allt\"agliche} Situationen im Stra\ss enverkehr dienen, m\"ussen aber ggf. gebrochen werden. Aus diesem Grund w\"urden f\"ur AA \glqq soft constraint\grqq{} (\autocite{Gerdes2015}, S. 94) gebraucht, die den Umst\"anden entsprechend gebrochen werden d\"urfen. Diese Forderung widerspricht der reinen Deontologie. 
\section{Utilitaristische Sichtweise}
	Computer sind f\"ur den Umgang mit Zahlen pr\"adestiniert. Die utilitaristische Ethik kann vergleichsweise einfach als Algorithmus implementiert werden. Elemente des Stra\ss enverkehrs k\"onnten als Variablen mit festgelegten Werten belegt, im Entscheidungsfall miteinander abgewogen werden und m\"ussen gewissen Konstanten entsprechen (z.B. StVO). Es gestaltet sich schwierig, sowohl den richtigen Wert jener Elemente zu ermitteln, als auch nicht-quantifizierbare Attribute -- z.B. der \glqq Wert\grqq{} eines Menschen -- f\"ur einen Computer messbar zu machen. 

	%Reschka \autocite{Reschka2015} spricht sich implizit f\"ur den utilitaristischen Ansatz aus, da durch kontinuierlicher Ermittlung und Einhaltung eines sicheren Zustandes im Falle eines Unfalls der entstehende Schaden m\"oglichst minimal bleiben soll (vgl. \autocite{Reschka2015}, S. 491). Zudem schl\"agt er vor, das Dilemma technisch zu umgehen: AA sollen sich durch Kommunikation untereinander vorausschauend f\"ur die Handlungsoption mit dem geringsten prognostizierten Schaden entscheiden (vgl. \autocite{Reschka2015}, S. 507).
	
	Gogoll und M\"uller \autocite{Gogoll2016} stellten sich zun\"achst die Frage: Sollte die Ethik eines AA durch eine festgelegte Instanz oder durch den Einzelnen selbst festgelegt werden (vgl. \autocite{Gogoll2016}, S. 3). Letzteres l\"asst zu bef\"urchten, dass der AA als \glqq moral proxy\grqq{} (\autocite{Gogoll2016}, S. 8) seines Besitzers dessen mitunter diskriminierende Haltung gegen\"uber bestimmten Bev\"olkerungsgruppen aus\"ubt. Ihren Berechnungen zufolge best\"unde das Optimum -- hier das Wohl der Allgemeinheit -- darin, ein utilitaristisches, staatlich vorgegebenes Modell zu implementieren, was im Extremfall die Opferung der eigenen Insassen des AA einschl\"o\ss e (vgl. \autocite{Gogoll2016}, S. 12 ff.). Jedoch r\"aumen sie ein, dass viele Menschen sich gegen einen selbst opfernden AA entscheiden w\"urden, obwohl dieser im Sinne aller w\"are (vgl. \autocite{Gogoll2016}, S. 18). 
	
	In der Annahme, dass sich Unf\"alle mit AA nicht vermeiden lassen werden, spricht Lin \autocite{Lin2015} gar von einer \glqq crash-optimization\grqq{} (\autocite{Lin2015}, S. 72), welche f\"ur AA in Betrachtung gezogen werden k\"onnte. Lin \autocite{Lin2015} f\"uhrt an, der Blickwinkel entscheide hierbei, \emph{wessen} Schaden minimiert werden soll. Wenn als \glqq Ziele\grqq{} eine Grundsch\"ulerin, ihre 80-j\"ahrige Gro\ss mutter oder ein massiver SUV\footnote{Sport Utility Vehicle} zur Auswahl st\"unden, g\"abe es unterschiedliche Arten, den minimalen Schaden zu berechnen. F\"ur die Insassen des AA w\"are das Kind das leichteste Objekt und somit bei einer Kollision eine geringere Gefahr, verletzt oder get\"otet zu werden. Ist beispielsweise nur ein Insasse im AA, k\"onnte es zielf\"uhrend sein, in den SUV zu steuern, da dessen Insasse(n) mit gro\ss er Wahrscheinlichkeit unverletzt blieben. Somit w\"are nur eine Person, der Insasse des AA, zu Schaden gekommen. Die \"altere Dame k\"ame unter dem Aspekt infrage, als dass sie bereits ein langes Leben gef\"uhrt hat und es ein Unrecht w\"are, das Leben von deutlich j\"ungeren Personen zu beenden (vgl. \autocite{Lin2015}, S. 70 ff.). Problematisch wird es, falls bekannt ist, \emph{wie} AA Unf\"alle zu vermeiden versuchen und \glqq other drivers may be tempted to `game' it\grqq{} (\autocite{Lin2015}, S. 81). Eine konkrete L\"osung stell Lin \autocite{Lin2015} nicht vor, jedoch kommt er zu dem Schluss, dass eine gesellschaftliche Diskussion \"uber Ethik in Bezug auf AA helfen kann, \emph{realistische} Erwartungen an diese Technologie zu stellen (vgl. \autocite{Lin2015}, S. 82).
	
	Die zuvor genannten Modelle sollten kritisch hinterfragt werden: Auf der einen Seite w\"urden bestimmte gesellschaftliche Gruppen (z.B. Senioren) \"ofter als \glqq Ziel\grqq{} von AA gew\"ahlt werden als andere. Auf der anderen Seite sollte es die Aufgabe jedes demokratischen Staates sein, das individuelle Leben zu sch\"utzen und nicht f\"ur das Wohl einer Mehrheit zu opfern (vgl. \autocite{Hevelke2015}, S. 622). Aus dieser Perspektive betrachtet w\"are im Szenario aus der Einleitung die beste Entscheidung gewesen, emph{keine} Entscheidung zu treffen und mit beiden Frauen zu kollidieren. Dies erscheint jedoch grausamer, als nur ein Todesopfer verantworten zu m\"ussen (vgl. \autocite{Lin2015}, S. 71).
	
	Denkbar w\"are zudem, dass ein utilitaristischer, potentiell sich selbst opfernder AA seine Einf\"uhrung in den allgemeinen Stra\ss enverkehr verz\"ogern oder gar verhindern k\"onnte, womit die erhofften Ziele des autonomen Fahrens nicht mehr erreicht w\"urden. Der Utilitarismus st\"unde sich paradoxerweise selbst im Wege (vgl. \autocite{Bonnefon1573}, S. 1575 f.).
\section{Weitere Sichtweisen}
	Aus dem vorhergehenden Kapitel wird ersichtlich, dass eine rein deontologische bzw. utilitaristische Ethik voraussichtlich von vielen Menschen abgelehnt w\"urde. Unter keinen Umst\"anden Regeln wie die StVO zu brechen entspricht nicht realistischen Situation im heutigen Stra\ss enverkehr und Berechnungen anzustellen, welche Person zum Wohle einer Mehrheit sterben m\"oge, scheint unvereinbar zu sein mit dem Recht auf Leben und k\"orperliche Unversehrtheit. 
	%Einen hybriden Ansatz konstruierten Gerdes und Thornton \autocite{Gerdes2015}, bei dem mithilfe von Kostenfunktionen Entscheidungen getroffen werden sollen:
	%\begin{quote}
	%	\glqq The challenge\dots becomes determining which principles are best described as a comparative weighting of costs from a consequentialist perspective and which form the more absolute rules of deontological ethics\grqq{} (\autocite{Gerdes2015}, S. 88).
	%\end{quote}
	%Erneut ist erkennbar, dass die Kostenberechnung ein moralisches Problem darstellt. Es stellt sich wiederholt die Frage, \emph{wessen} Schaden werden soll.
	
	In Anbetracht der erwarteten Vorz\"uge des autonomen Fahrens mag es ein pragmatischer Ansatz sein, Dilemma-Situationen als Ausnahmef\"alle zu akzeptieren. Laut Gasser \autocite{Gasser2015} sind solche zugespitzten Szenarien kritisch zu bewerten, da der allgemeinen Stra\ss enverkehr zu dynamisch sei, als dass es zwangsweise zu einem t\"odlichen Personenschaden kommen muss. Vielmehr k\"onnten AA durch eine defensive Fahrweise solche Situationen rechtzeitig erkennen und ggf. vermeiden. Sollten Dilemma, entgegen seiner Meinung, von gr\"o\ss erer Relevanz sein, m\"usse man ethische Entscheidungskriterien finden, die allgemein anerkannt seien. (vgl. \autocite{Gasser2015}, S. 555 ff.). Folgendes sollte jedoch nicht vergessen werden: \glqq Auch kommt es in \glq Dilemma-Situationen\grq{} unterschiedslos im Fall eines menschlichen Fahrers wie im Fall maschinellen Wirkens letztlich zu einer Schädigung.\grqq{} (\autocite{Gasser2015}, S. 558). 
	
	Bezogen auf das letzte Zitat best\"unde die Option, den Insassen eines AA schlicht als \glqq Notfall-Fahrer\grqq{} in Dilemma-Situationen die Verantwortung zu \"ubergeben. Dilemma lassen sich in diesem Modell offensichtlich nicht l\"osen, jedoch entf\"allt somit die ethische Verantwortung der Entscheidungsfindung. Der menschliche Fahrer wird den drohenden Unfall nicht verhindern k\"onnen, da die \"Ubergabe des Fahrauftrags Zeit beansprucht und der Unfall sich in dieser Zeit bereits ereignet haben wird. Fordert man vom Fahrer wiederum, stets konzentriert den Verkehr zu beobachten, f\"uhrt dies den Zweck eines AA ad absurdum. Wolf \autocite{Wolf2015} formuliert wie folgt: \glqq einerseits werden Systemfunktionen aufgrund der Fehlerhaftigkeit des Menschen automatisiert, und anderseits soll genau dieser Mensch das System überwachen und im Notfall als Rückfalloption zur Verfügung stehen\grqq{} (\autocite{Wolf2015}, S. 105). Hevelke und Nida-R{\"u}melin \autocite{Hevelke2015} prognostizieren zudem, dass sich mit AA im Durchschnitt nur ca. alle 2 Millionen Kilometer ein Unfall ereignen wird (vgl. \autocite{Hevelke2015}, S. 624 f.). 
	
	Abschlie\ss end sei noch ein L\"osungsvorschlag von Scholz und Kempf \autocite{Scholz2016} vorgestellt. Dilemma sollen durch vier L\"osungswege vermieden werden: eine graduelle Einf\"uhrung von AA in bestimmten Szenarien, Koordination (zwischen AA, anderen Verkehrsteilnehmern und der Infrastruktur), eine defensive Fahrweise und ein nicht-deterministisches Entscheidungssystem f\"ur Dilemma-Situationen. Die Ans\"atze zielen darauf ab, die gesellschaftliche Akzeptanz f\"ur AA nach ihrer Einf\"uhrung zu festigen, da sie zun\"achst nur in bestimmten, tendenziell vorhersehbaren Szenarien (z.B. Autobahn) eingesetzt w\"urden und sich etablieren k\"onnen. Eine vernetzte Infrastruktur in Kombination mit einer zur\"uckhaltenden Fahrweise kann im Laufe der fortschreitenden Verbreitung von AA auch in urbanen Gebieten drohende Konflikte im Idealfall vermeiden (vgl. \autocite{Scholz2016}, S. 223 ff.). Aus ethischer Sicht ist der Vorschlag, ein nicht-deterministisches Entscheidungssystem zu implementieren, ambivalent. Verhielte sich der AA \glqq wie ein perfekter Autofahrer\grqq{} (\autocite{Scholz2016}, S. 226), w\"are die Diskussion \"uber ethische AA unbegr\"undet, da an menschliche Fahrer keine besondere ethischen Forderungen gestellt worden sind. Andererseits k\"onnten Todesf\"alle im Stra\ss enverkehr auftreten, die mit einem utilitaristischen AA h\"atten verhindert werden k\"onnen. 
\section{Fazit}
	Es konnte keine \"Ubereinstimmung gefunden werden, welche Ethik die \glqq richtige\grqq{} sei. Welche Instanz dar\"uber zu entscheiden hat ergab zum Teil sogar widerspr\"uchliche Ansichten \autocite{Gogoll2016,Hevelke2015}. Man k\"onne zudem von \glqq den Programmierern dieser Fahrzeuge\dots nicht das Auflösen moralischer Dilemmata [erwarten]\dots wenn selbst in der Moralphilosophie keine Einigkeit herrscht\grqq{} (\autocite{Scholz2016}, S. 222). Generell scheint der utilitaristische Ansatz eher Zustimmung zu finden als andere, wobei jedoch die fehlende Achtung vor dem individuellem Leben scharf kritisiert wird. Das Dilemma kann mit technischen Mitteln -- z.B. einer defensiven Fahrweise -- besser umgangen, aber im Eintrittsfall nicht mehr gel\"ost werden. Es liegt in der Natur eines Dilemmas, dass es keine zufriedenstellende L\"osung geben kann. 
	
	Trotzdem besteht Einigkeit dar\"uber, dass die Einf\"uhrung von AA nicht wegen seltener Extremf\"alle verhindert werden sollte. Transparenz \"uber die Mechanismen von AA und eine \"offentliche Diskussion \"uber deren Ethik k\"onnen helfen, den Entscheidungsvorgang eines AA zu verstehen und nicht als \glqq Black-Box\grqq{} aufzufassen. 
 
%Leitfragen nochmal aufgreifen (sind welche offen geblieben?)
%Plaedieren fuer defensive Fahrweise

	%Man stelle sich vor: Ein Krankenwagen erreicht verz\"ogert einen Unfallort, weil ein menschlicher Autofahrer der StVO gem\"a\ss\ nicht die rote Ampel \"uberfahren hat, obwohl es ihm m\"oglich gewesen w\"are.
	%Speziell in Deutschland aufgrund seiner nationalsozialistischen Vergangenheit w\"are ein utilitaristischer Ansatz nur schwer vorstellbar (vgl. \autocite{Gless2016}, S. 575).

\newpage
\printbibliography
\end{document}