Andreas Reschka: Sicherheitskonzepte fuer autonome Fahrzeuge
technischer Natur, Ethik wird benoetigt aber es wird keine konkrete angegeben. Da Schaden minimalisiert werden soll, geht der Autor vmtl von Utili aus. Regeln duerfen im Notfall gebrochen werden (StVO). Mit Kommunikation mit anderen Fahrzeugen als Loesung des Dilemmas (damit A nicht den Menschen umfaehrt, weicht A in den Gegenverkehr aus und hat entgegenkommendes B gebeten an den Rand zu fahren). generell soll ein sicherer Zustand erreicht werden (Risiken senken zB durch reduzierte Fahrgeschwindigkeit, sofern zumutbar)
"Für ein autonomes Fahrzeug ist daher eine kontinuierliche Ermittlung des aktuellen Risikos
basierend auf der aktuellen Situation und ein Abgleich des Risikos mit dem Schwellwert,
der als gerade noch zumutbar gilt, notwendig." S. 491
1, 2, technik


Tom Michael Gasser: Grundlegende und spezielle Rechtsfragen für autonome Fahrzeuge
geht eher um die Haftbarkeit und ob Dilemma nicht vermieden werden koennen. Existiert so ein Dilemma ueberhaupt, kann im Strassenverkehr so eine Zuspitzung passieren?
Abwaegen von Leben ist unzulaessig
Transparenz und muss diskutiert werden, eventuell in Form eines "Kataloges mit anerkannten Entscheidungskriterien fuer solche Situationen" S. 558, sofern Dilemma relevant werden sollten und doch nicht so selten sind.
"Auch kommt es in „Dilemma-Situationen“ unter-
schiedslos im Fall eines menschlichen Fahrers wie im Fall maschinellen Wirkens letztlich
zu einer Schädigung." S. 558
1, -2, 


Ingo Wolf: Wechselwirkung Mensch und autonomer Agent
"Bainbridge [7]
spricht in diesem Zusammenhang von der „Ironie der Automatisierung“ – einerseits werden
Systemfunktionen aufgrund der Fehlerhaftigkeit des Menschen automatisiert, und ander-
seits soll genau dieser Mensch das System überwachen und im Notfall als Rückfalloption
zur Verfügung stehen." S. 105
Kritik zu: Mensch uebernimmt


Patrick Lin: Why Ethics Matters for Autonomous Cars !!!! Nochmal die Seitenzahlen checken!!
Utili scheint nicht vereinbar zu sein zB. mit deutschem Grundgesetz. Aber im Zweifelsfall keine Entscheidung treffen und beide umbringen klingt noch schlimmer als eine unmoralische Entscheidung zu treffen. 
Absehbare Probleme: diskriminierung wegen z.B. Alter

Es kann sein dass Dilemma nie auftritt bzw die Vorteile von AA weit ueberwiegen werden

Eine Loesung: im Dilemma dem Fahrer Kontrolle zurueckgeben. Eher bloed, braucht ggf. einige Sekunden um sich einen Ueberblick zu verschaffen (und die Zeit ist ja schon knapp, daher unrealistisch) (weitere Ueberlegung: den Fahrer verpflichten immer stets wachsam zu sein? Unrealistisch, dafuer wuerden ja AA eingefuehrt, und Fahrer haette eine noch monotonere Aufgabe als jetzt schon zB auf der Autobahn. Dazu hat eine anderer Autor geschrieben, siehe dort ;P)

Crash-Vermeidung allein reicht nicht, da es immer zu Unfaellen kommen wird. Daher: "crash-optimization" S. 71
" to
choose the course of action that will likely lead to the least amount of harm" S. 71 -> klingt nach Utili
Dieses Targeting (aus militarischen Bereich...?) kann nach verschiedenen Gesichtpunkten agieren (Insassen schuetzen, alle Verkehrsteilnehmer schuetzen, ...): Das kleine Maedchen toeten weil ein kleineres Gewicht den Insassen wohl weniger schadet. Oder das Auto extra in ein massigeres Auto fahren, da im leichtere Auto vmtl eher Tote oder da sassen mehr Insassen. Targeting kann aber systematisch Gruppen/Dinge diskriminieren da sie eher ausgewaehlt werden. Inhaber von "gefaehrlichen" Autos/SUVs ggf. rechtlich verantwortlich zu machen, weil er durch Nutzung dieses Fahrzeugs anderen ein Risiko ausgesetzt hat. (kann man das nicht heute auch schon sagen?)
Dann Beispiel: Motorradfahrer mit und ohne Helm (wer sollte ausgewaehlt werden? Mit Helm weil hoehere Chancen oder ohne Helm als Bestrafung?) (meine Kritik: entspraeche nicht ganz Utili, da absehbare Nebenfolge [keiner will mehr Helme tragen] schlechten Nutzen haette; wuerde der ohne Helm jetzt gewaehlt, haette es den besten Nutzen, auch wenn er stirbt)

Es gibt (zu) viele Aspekte zu beruecksichtigen, was den geringsten Schaden anrichtet. Sind Insassen angeschnallt, wird gefaehrliche Fracht geladen, wie wird sich Tier/Fussgaenger verhalten, ist hinter mir ein LKW (also Vollbremsung evtl mein Tod), 
Dennoch: Bremsen als Default-option

"Again, in a real-world accident today, a human driver usually has neither the time nor
the information needed to make the most ethical or least harmful decisions. A person who
is startled by a small animal on an otherwise-uneventful drive may very well react poorly.
He might drive into oncoming traffic and kill a family, or oversteer into a ditch and to his
own death. Neither of these results, however, is likely to lead to criminal prosecution by
themselves, since there was no forethought, malice, negligence, or bad intent in making a
forced, split-second reaction. But the programmer and OEM do not operate under the
sanctuary of reasonable instincts; they make potentially life-and-death decisions under no
truly urgent time-constraint and therefore incur the responsibility of making better
decisions than human drivers reacting reflexively in surprise situations" S. 75

Kritik an Konsequenzialismus: self-sacrifice (als ausserste Konsequenz). vielleicht, haette man die  Zeit, moechte man sich selbst opfern, jedoch kann man so nicht selbst die Entscheidung aus freien Stuecken treffen. 
Wird die moral calculation auch richtig berechnet? Wahrscheinlichkeiten?
Koennte am moraischten sein, aber sollte besser oeffentlich diskutiert werden, damit Oeffentlichkeit gnaediger damit umgeht.
" the
problem may not be with the ethics but with a lack of discussion about ethics" S. 77
"Either the programmer did so deliberately, or
she did it unintentionally, unaware that this was a possibility. If the former, then this could
be construed as premeditated homicide; and if the latter, gross negligence.
" S. 78 

Transparenz ueber die Algorithmen gefordert, jedoch kein Allheilmittel. 
Was werden die Hersteller tun? Um fein raus zu sein immer die kontrolle im letzten Augenblick an den Fahrer zurueckgeben? Besser 5 sterben zu lassen als 1 gezielt als Ziel auszusuchen. 
Andere Problemstellung: Fahrzeuge in oeffentlicher Hand? Oder:
"If the crash-avoidance system of a robot car is generally known,
then other drivers may be tempted to “game” it" S. 81

Fazit: Crash avoidance nicht genug, sie brauchen ethische Richtlinien um entscheidungen zu treffen (ungenau). Zudem muessen alle anderen Teilnehmer aufgeklaert werden, damit es zu keinen boesen Ueberraschungen kommt. Wegen Ethic: irgendjemand wird immer unzufrieden sein/nicht zustimmen 
Also: chrash-optimierung, offener Code, Aufklaerung der Allgemeinheit, da sonst zu hohe Erwartungen gestellt werden bis der grosse Knall kommt. 


J. Christian Gerdes, Sarah M. Thornton: Implementable Ethics for Autonomous
Vehicles
"Very direct analogies can be drawn
between the frameworks of consequentialism and deontological ethics in philosophy and
the use of cost functions or constraints in optimal control theory. These analogies enable
ethical principles that can be described as a cost or a rule to be implemented in a control
algorithm alongside other objectives. The challenge then becomes determining which
principles are best described as a comparative weighting of costs from a consequentialist
perspective and which form the more absolute rules of deontological ethics." S. 88

Kostenfunktion aus dem Konsequenzialismus entnommen. Alle Objekte zB mit "Gefahr" oder "Risiko" zum Fahrzeug bewerten. Personenschaden wird nach schwere quantifiziert. Wird viel Rechenleistung erfordern, saemtliche Ausgaenge einer Situation zu berechnen. Wuerden die insassen als wertvoller bewertet, wurde das Auto unwahrscheinlich von der allgemeinheit akzeptiert. 
Purer Konseq waere wohl undurchfuehrbar, da die kostenfunktion mitunter falsch berechnet wuerde (schlechte Lichtverhaeltnisse, Alter des Menschen falsch erkannt...)

Deonto. Regeln als Constraints (Zwaenge, Verbote): Regeln einhalten, Regeln haben Wert/oder Malus. Wenn es zu Constraint-Konflikt kommt (Menschenleben schuetzen vs. Stoppschild), muss ein Constraint gebrochen werden ("soft constraint" S. 94); normalerweise reichen die Constraints aus, aber im Dilemma darf es mit geringst moeglichen Malus gebrochen werden. 
hybrid framework das beim Dilemma wieder Konseq wird. 
Anderer Deonto Anlauf: Asomovs Three Laws of Robotics als Grundlage
nicht perfekt, und vielleicht akzeptierne die ELute auch dass es hierbei keine optimale Loesung gibt, aber immer das Leben an hoechster Stelle steht. 

"1. An automated vehicle should not collide with a pedestrian or cyclist.
2. An automated vehicle should not collide with another vehicle, except where avoiding
such a collision would conflict with the First Law.
3. An automated vehicle should not collide with any other object in the environment,
except where avoiding such a collision would conflict with the First or Second Law
.
An automated vehicle must obey traffic laws, except where obeying such laws would
conflict with the first three laws. S. 96 ff.
Also StVO als Grundlage und diese fiktiven Regeln uebergeordnet. 
"The ultimate answer for automated vehicles
probably depends upon whether society comes to view these machines as simply more
capable cars or robots with their own sense of agency and responsibility. If we expect the
cars to bear the responsibility for their actions and make ethical decisions, we may need to
be prepared to cede more control to them. Gaining the trust required to do that will no
doubt require a certain transparency to their programmed priorities and a belief that the
decisions made in critical situations are reasonable, ethical and acceptable to society." S. 101

